{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt','rb') as f: # Unpickling \n",
    "    train_data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt','rb') as f:  # Unpickling\n",
    "    test_data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=test_data+train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "### Setting up vocabulary of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=set()\n",
    "for story,ques,ans in all_data:\n",
    "    vocab=vocab.union(set(story))\n",
    "    vocab=vocab.union(set(ques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len=len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest Story\n",
    "all_story_len=[len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len=max(all_story_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ques_len=max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ques_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words \n",
    "\n",
    "tokenizer= Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 1,\n",
       " 'mary': 2,\n",
       " 'picked': 3,\n",
       " 'bedroom': 4,\n",
       " 'went': 5,\n",
       " 'football': 6,\n",
       " 'travelled': 7,\n",
       " 'grabbed': 8,\n",
       " 'bathroom': 9,\n",
       " 'john': 10,\n",
       " '.': 11,\n",
       " 'back': 12,\n",
       " 'journeyed': 13,\n",
       " 'kitchen': 14,\n",
       " 'moved': 15,\n",
       " 'took': 16,\n",
       " 'up': 17,\n",
       " 'in': 18,\n",
       " 'daniel': 19,\n",
       " 'no': 20,\n",
       " 'dropped': 21,\n",
       " 'garden': 22,\n",
       " 'left': 23,\n",
       " 'sandra': 24,\n",
       " 'discarded': 25,\n",
       " 'put': 26,\n",
       " '?': 27,\n",
       " 'the': 28,\n",
       " 'apple': 29,\n",
       " 'to': 30,\n",
       " 'milk': 31,\n",
       " 'office': 32,\n",
       " 'yes': 33,\n",
       " 'got': 34,\n",
       " 'is': 35,\n",
       " 'hallway': 36,\n",
       " 'there': 37}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text=[]\n",
    "train_ques_text=[]\n",
    "train_answer=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,ques,ans in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_ques_text.append(ques)\n",
    "    train_answer.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq=tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data,word_index=tokenizer.word_index,max_story_len=max_story_len,max_ques_len=max_ques_len ):\n",
    "    # Stories=X\n",
    "    X=[]\n",
    "    # Questions=Xq\n",
    "    Xq=[]\n",
    "    # Y Correct Answer (Yes/No)\n",
    "    Y=[]\n",
    "    \n",
    "    for story,query,answer in data:\n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        \n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "         # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y=np.zeros(len(word_index)+1)\n",
    "        \n",
    "        y[word_index[answer]] =1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "        # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return(pad_sequences(X,maxlen=max_story_len),pad_sequences(Xq,maxlen=max_ques_len),np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train,queries_train, answer_train=vectorize_stories(train_data)\n",
    "inputs_test,queries_test, answer_test=vectorize_stories(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 28,  4, 11],\n",
       "       [ 0,  0,  0, ..., 28, 22, 11],\n",
       "       [ 0,  0,  0, ..., 28, 22, 11],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 28, 29, 11],\n",
       "       [ 0,  0,  0, ..., 28, 22, 11],\n",
       "       [ 0,  0,  0, ..., 29, 37, 11]], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       497.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answer_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PlaceHolder for input  shape=(max_story_len,batch_size)\n",
    "input_sequence=Input(max_story_len,)\n",
    "question=Input((max_ques_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#(samples,story_maxlen,embedding_dim)A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_ques_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#(samples,story_maxlen,max_ques_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION ENCODER \n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=max_ques_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#(samples,query_maxlen,embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODED <----- ENCODER(Input)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded= question_encoder(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "match= dot([input_encoded_m,question_encoded],axes=(2,2))\n",
    "match=Activation('softmax')(match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "response= add([match,input_encoded_c])\n",
    "response=Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "\n",
    "answer=concatenate([response,question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate_1')>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "\n",
    "answer=LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "\n",
    "answer=Dropout(0.5)(answer)\n",
    "answer=Dense(vocab_size)(answer) # (sample,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model([input_sequence,question],answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, None, 64)     2432        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 6, 64)        2432        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_3[0][0]               \n",
      "                                                                 sequential_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, None, 6)      228         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 4s 7ms/step - loss: 9.5433 - accuracy: 0.2970 - val_loss: 16.1181 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 11.3759 - accuracy: 0.3721 - val_loss: 16.1181 - val_accuracy: 0.5030\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 14.0032 - accuracy: 0.4725 - val_loss: 16.1181 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 12.4782 - accuracy: 0.4604 - val_loss: 16.1181 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 10.3945 - accuracy: 0.4710 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 8.1825 - accuracy: 0.4660 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.4837 - accuracy: 0.4814 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.5215 - accuracy: 0.5035 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.2341 - accuracy: 0.4983 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 8.5624 - accuracy: 0.4943 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.2800 - accuracy: 0.5007 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.6570 - accuracy: 0.4900 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.5810 - accuracy: 0.5036 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.5172 - accuracy: 0.5011 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 8.6747 - accuracy: 0.5011 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 9.2537 - accuracy: 0.4952 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 9.5150 - accuracy: 0.4981 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.4113 - accuracy: 0.4896 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.7191 - accuracy: 0.4991 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.3337 - accuracy: 0.4984 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 10.2163 - accuracy: 0.5032 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.5849 - accuracy: 0.5142 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 10.1432 - accuracy: 0.5056 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 10.0321 - accuracy: 0.5011 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.8242 - accuracy: 0.5037 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 10.8472 - accuracy: 0.4974 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 10.7115 - accuracy: 0.4993 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 10.3464 - accuracy: 0.5022 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 11.0711 - accuracy: 0.4909 - val_loss: 16.1181 - val_accuracy: 0.5030\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 12.3527 - accuracy: 0.5001 - val_loss: 16.1181 - val_accuracy: 0.5030\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 12.0409 - accuracy: 0.4994 - val_loss: 0.1566 - val_accuracy: 0.5030\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 11.3455 - accuracy: 0.4976 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.7458 - accuracy: 0.5064 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.0314 - accuracy: 0.5000 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.0907 - accuracy: 0.5014 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 8.9253 - accuracy: 0.5009 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.4245 - accuracy: 0.5018 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.7277 - accuracy: 0.5073 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.0881 - accuracy: 0.4935 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.4249 - accuracy: 0.5058 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.4721 - accuracy: 0.5056 - val_loss: 8.1074 - val_accuracy: 0.5030\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.3012 - accuracy: 0.4973 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 10.5647 - accuracy: 0.5012 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.9574 - accuracy: 0.5054 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.5629 - accuracy: 0.5007 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.7608 - accuracy: 0.4976 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.9449 - accuracy: 0.5005 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.8884 - accuracy: 0.4978 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.3714 - accuracy: 0.5038 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.8950 - accuracy: 0.5018 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.8218 - accuracy: 0.4993 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.4828 - accuracy: 0.5024 - val_loss: 8.1074 - val_accuracy: 0.5030\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.4823 - accuracy: 0.4941 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 10.4512 - accuracy: 0.5011 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.3892 - accuracy: 0.5060 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 11.0305 - accuracy: 0.5025 - val_loss: 8.9265 - val_accuracy: 0.5030\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 11.1035 - accuracy: 0.4847 - val_loss: 8.0107 - val_accuracy: 0.5030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.4308 - accuracy: 0.4934 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.4300 - accuracy: 0.4940 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.3136 - accuracy: 0.4893 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.1314 - accuracy: 0.5001 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.7559 - accuracy: 0.4968 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.9226 - accuracy: 0.5004 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 9.9034 - accuracy: 0.5021 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 9.9920 - accuracy: 0.4940 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 10.0699 - accuracy: 0.4918 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 10.2393 - accuracy: 0.4986 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.8317 - accuracy: 0.4958 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.2674 - accuracy: 0.5025 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.9880 - accuracy: 0.5045 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 10.1936 - accuracy: 0.4959 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.9978 - accuracy: 0.5044 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.4102 - accuracy: 0.5005 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.2698 - accuracy: 0.4978 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.0192 - accuracy: 0.4917 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 8.9668 - accuracy: 0.4962 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 8.9155 - accuracy: 0.4934 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 9.0083 - accuracy: 0.4923 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 8.8364 - accuracy: 0.5024 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.1367 - accuracy: 0.5017 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.1725 - accuracy: 0.4933 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.9227 - accuracy: 0.5016 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.1685 - accuracy: 0.4974 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.2566 - accuracy: 0.4944 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 9.2455 - accuracy: 0.4917 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.9551 - accuracy: 0.5078 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.0836 - accuracy: 0.5003 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.0230 - accuracy: 0.4961 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.1665 - accuracy: 0.4939 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 8.9132 - accuracy: 0.5041 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 8.9699 - accuracy: 0.5068 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 8.7954 - accuracy: 0.4998 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.3062 - accuracy: 0.4934 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.1097 - accuracy: 0.4938 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 8.9292 - accuracy: 0.4995 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 9.0810 - accuracy: 0.5012 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.1350 - accuracy: 0.4894 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 8.8666 - accuracy: 0.4941 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.1770 - accuracy: 0.4873 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.0099 - accuracy: 0.4995 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.4697 - accuracy: 0.5022 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.6487 - accuracy: 0.4920 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.3765 - accuracy: 0.4994 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.3882 - accuracy: 0.4982 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 9.2799 - accuracy: 0.4976 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.1041 - accuracy: 0.5012 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.0795 - accuracy: 0.5010 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.3398 - accuracy: 0.4990 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.3699 - accuracy: 0.4966 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.5388 - accuracy: 0.5009 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.7917 - accuracy: 0.5002 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.7125 - accuracy: 0.5035 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.6570 - accuracy: 0.4954 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.2147 - accuracy: 0.4985 - val_loss: 8.0107 - val_accuracy: 0.5030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.1051 - accuracy: 0.5001 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.2465 - accuracy: 0.5030 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.2594 - accuracy: 0.4938 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 9.1891 - accuracy: 0.4959 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 9.3804 - accuracy: 0.4975 - val_loss: 8.0107 - val_accuracy: 0.5030\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.5014 - accuracy: 0.5031 - val_loss: 8.0107 - val_accuracy: 0.5030\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([inputs_train,queries_train],answer_train,batch_size=32,epochs=120,validation_data=([inputs_test,queries_test],answer_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120epoch.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting our training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on given testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('chatbot_120epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results=model.predict(([inputs_test,queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  10.831581\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing our own story and questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story=\"John left the kitchen . Sandra dropped the football in the garden .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question=\"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=[(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['John',\n",
       "   'left',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'dropped',\n",
       "   'the',\n",
       "   'football',\n",
       "   'in',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'the', 'football', 'in', 'the', 'garden', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_question, my_ans=vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['John',\n",
       "   'left',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'dropped',\n",
       "   'the',\n",
       "   'football',\n",
       "   'in',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'the', 'football', 'in', 'the', 'garden', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,\n",
       "        23, 28, 14, 11, 24, 21, 28,  6, 18, 28, 22, 11]], dtype=int32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results=model.predict(([my_story,my_question]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 38)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  10.834788\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
